{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYSu48huSUW",
        "outputId": "64e4984b-4b62-4709-847a-a021d4730a8f"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain openai tiktoken chromadb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFB7J_u_3L",
        "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
      },
      "outputs": [],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AnZQpL_IZZZ"
      },
      "source": [
        "# LangChain multi-doc retriever with ChromaDB\n",
        "\n",
        "***New Points***\n",
        "- Multiple Files\n",
        "- ChromaDB\n",
        "- Source info \n",
        "- gpt-3.5-turbo API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "## Setting up LangChain \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UcQKUId3X2M"
      },
      "source": [
        "## Load multiple and process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "outputs": [],
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "outputs": [],
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlU5AlqY4gwj",
        "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
      },
      "outputs": [],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
      },
      "outputs": [],
      "source": [
        "texts[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYsIy8F4cdm"
      },
      "source": [
        "## create the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_eTIZwf4Dk2",
        "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
      },
      "outputs": [],
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "\n",
        "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts, \n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "outputs": [],
      "source": [
        "# persiste the db to disk\n",
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-h1y_eAHmD-",
        "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
      },
      "outputs": [],
      "source": [
        "# Now we can load the persisted database from disk, and use it as normal. \n",
        "vectordb = Chroma(persist_directory=persist_directory, \n",
        "                  embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLXR-XT0JoI"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYA-H59u0Skn"
      },
      "outputs": [],
      "source": [
        "docs = retriever.get_relevant_documents(\"How much money did Pando raise?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0iAuh_B0ZjE",
        "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H4N0IhRM0hHL",
        "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
      },
      "outputs": [],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jXL9u-u0prF",
        "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
      },
      "outputs": [],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions \n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
        "                                  chain_type=\"stuff\", \n",
        "                                  retriever=retriever, \n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
      },
      "outputs": [],
      "source": [
        "# full example\n",
        "#query = \"How much money did Pando raise?\"\n",
        "#query = \"What make Prometheus so impressed ?\"\n",
        "query = \"What the different between DeepFloyd IF and models such as Stable Diffusion and DALL-E 2 ?\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRm73t3rNt2",
        "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
      },
      "outputs": [],
      "source": [
        "# break it down\n",
        "query = \"What is the news about Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "# process_llm_response(llm_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-e6fh6rNwz",
        "outputId": "4b8d1e0e-b039-4e21-c233-a6c308cc5e25"
      },
      "outputs": [],
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "19c63b88-33e2-4400-eede-f2678231eccb"
      },
      "outputs": [],
      "source": [
        "query = \"What did databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "4f4a7dfb-0f5b-4b72-b678-6def5d056d20"
      },
      "outputs": [],
      "source": [
        "query = \"What is generative ai?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "85124452-c208-4ec4-a35d-be28503ddc42"
      },
      "outputs": [],
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIhZWAR5n3X",
        "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
      },
      "outputs": [],
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_lp0_796P_-",
        "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxVCnNi5h1-"
      },
      "source": [
        "## Deleteing the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xmepGJ2GAE",
        "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
      },
      "outputs": [],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl84qGQt5Wu5"
      },
      "outputs": [],
      "source": [
        "# To cleanup, you can delete the collection\n",
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "# delete the directory\n",
        "!rm -rf db/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2r0ZIBPJp-K"
      },
      "source": [
        "## Starting again loading the db\n",
        "\n",
        "restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pc7CM_mTQAt",
        "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
      },
      "outputs": [],
      "source": [
        "!unzip db.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us3F8ZKeRiz2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK1nY4PkKYGo"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "396RyNbS4EXx",
        "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'db'\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory=persist_directory, \n",
        "                  embedding_function=embedding,\n",
        "                   )\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3vkSxxYKCZ9"
      },
      "outputs": [],
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsR60NH5KCfj"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions \n",
        "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm, \n",
        "                                  chain_type=\"stuff\", \n",
        "                                  retriever=retriever, \n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWulTG0eKCfk"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDp-g2FtKCfk",
        "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
      },
      "outputs": [],
      "source": [
        "# full example\n",
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPl26c-TbWw"
      },
      "source": [
        "### Chat prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwyuhrpu5XqM",
        "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcWXvSCHRvHO",
        "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978QWCeJSRdu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
